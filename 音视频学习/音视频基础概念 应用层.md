## 从零开始的音视频基础

### 声音

声音是一种压力波，物体的振动带动周围空气的振动，产生疏密相间的空气纵波，传入人耳引起听觉

声波由频率、振幅和相位（波形）组成。

频率决定音高，振幅决定响度，波形（主要部分）决定音色

> 关于音色比较复杂，可以参考这篇文章 https://zhuanlan.zhihu.com/p/86355156

人耳听觉的频率范围是`20Hz - 20kHz`，但不同频率下，听力的感觉是不同的。下图是等响曲线，表示在各个频率下需要多强的声压才能产生相同强度的听觉

![查看源图像](https://pic3.zhimg.com/v2-72c7bc37f546fdf63bfd823df11b4d59_r.jpg)

由于声压的绝对数值变化范围太宽，且人耳对声音的感受，和声压的变化不是线性相关的，而是呈对数相关。所以对声压进行对数处理，得到分贝的概念
$$
N=10\space*\space lg(被测量\space/\space参考量)
$$
一般的声音通过空气作为介质传播，但声音还可以通过固液相的其他物质来传播，不同介质的传播速度也不同，最常见是颅骨传导声音

生活中经常能听到回声，但理论上任何声音的传播都伴随着复杂的回声。人脑的极限是`80ms`，间隔小于这个阈值的声音传入人耳是无法区分的

声波是含能量的，特定情况下能通过共鸣的方式把能量传递给另一个物体

### 数字音频

数字化的过程是对声音进行，采样、量化和编码

采样遵循奈奎斯特定理，一般的采样频率是`44.1kHz`

量化是将声音的幅值切分成若干区间，如用16 bit的数位量化声音，那么一共有65536个区间

编码将采样和量化后的数据组织并存储起来。一般的音频裸数据格式都是脉冲编码调制 `PCM`，需要三个量来描述这段音频，位深度（如16 bit），采样率（如`44.1kHz`），声道数（如2声道）

> 关于声道，可参考 https://www.zhihu.com/question/32198079/answer/55440380

假设以上述默认值进行编码一个 60 s 的音频，其占用的存储空间（裸数据）应该是
$$
44100\space*\space16\space*2\space*\space60\space/\space8\space1024\space=10.09MB
$$

### 音频编码

音频的裸数据用于网络传输显然太大，所以有一些压缩编码的方法

压缩分为无损和有损两种。无损指可以通过压缩数据完全复原原始数据，压缩比较低。有损指丢弃一部分不太重要的原始信息，压缩比较高

压缩算法之所以能在丢弃部分数据后保持良好的听觉效果，是因为人耳存在频域掩蔽效应和时域掩蔽效应，即一部分声信号被其余声信号掩盖，人耳天然就听不到

##### `WAV` 编码

它是一种没有压缩的编码，仅仅是在 `PCM` 的基础上加上一些标注信息。它的一种实现是在裸数据前加一个44 字节的文件头，描述位深度、采样率、声道等

这种格式是最通用的，数据也没有任何丢失，几乎所有平台和音视频软件都支持

##### `MP3` 编码

应用最广泛的有损压缩之一，它的一种实现是 `LAME` 编码算法，在中高码率时听感非常接近 `WAV`。压缩比也较高，兼容性强

##### `AAC` 编码

新一代的有损压缩，分为三个子类

`LC-AAC` 用于中高码率（`80Kbit/s`以上）

`HE-AAC` 用于中低码率（`80Kbit/s`以下）

`HE-AAC-V2` 用于低码率 （`48Kbit/s` 以下）

这些编码技术在小于`128Kbit/s` 的码率下性能比高，**常用于视频中的音频轨的编码**

##### `Ogg` 编码

算法性能极佳，可以用比 `MP3` 更低的码率实现比 `MP3` 更好的音质，高中低码率下性能都很好

缺点是兼容性不好，不支持流媒体，目前应用不够广泛

### 图像

从手机屏幕出发，分辨率位1280 x 720的屏幕，水平方向有 720 个像素点，垂直方向是 1280 个，总计1280 x 720个

每个像素点由3个子像素点构成，分别对应 `RGB` 三个通道。所以手机屏幕的图像源自自身发光，而生活中的物体颜色源于对自然光的反射

`RGB`中每个子像素点，一般用0-255的整数表示，即8个bit表示一个子像素。但这不是绝对的，不同的`RGB`格式可能用不同位数的bit表示像素。比如 `RGBA_8888`用32个bit表示一个像素

为了节省空间，还有一种像素表示形式是 `YUV` 格式。它将图像分为亮度和色彩两部分，是视频编码和通信中最常用的格式。其与`RGB`的转换如下

![img](https://pic3.zhimg.com/80/v2-7cb7c3b35a16cf92039f455e3eb88582_1440w.jpg)

### 视频编码

类似音频编码中利用人耳的掩蔽效应，视频编码也是利用人眼的一些视觉特性，比如对亮度敏感，对颜色不敏感，对静态事物分辨率高，对动态事物分辨率低，最高分辨率是`24Hz`，超过之后就形成连续感等等

视频编码分为帧间编码和帧内编码，前者去除时间上的冗余，后者去除空间上的冗余

视频编码格式分很多种，如`MPEG1, MPEG2, MPEG4 AVC, H.261, H.262, H.263, H.264, H.265`

**目前使用最多的是 `H.264`**（`MPEG4`在某种意义上和它是兼容的），相对性能最好，广泛用于普通视频传输和流媒体技术

编码技术中的一些术语：

##### `IPB` 帧

I 帧是帧内编码帧，又叫做关键帧。这种帧通常是 `GOP`的第一个帧，压缩比不是非常高，保留了所有重要信息，作为视频解码的参考帧，在某种意义上可以理解为一幅普通的静态图像。这种帧能去除空间冗余

P 帧是前向预测编码帧，解码时需要依赖视频序列前面已经解码的参考帧，如 I 帧 P 帧。能去除时间冗余

B 帧是双向预测编码帧，解码时需要同时依赖视频序列前后已经解码的参考帧，如 I 帧，P 帧。能去除时间冗余。 P B帧的压缩比通常都很高

 事实上，`H.264`中还有一种 D 帧，用于多帧预测技术，`STFW`吧

`PTS & DTS`

`DTS` = Decoding Time Stamp，用于解码视频

`PTS` = Presentation Time Stamp，用于解码的同时同步输出视频

之所以要分成两部分，是因为 I P B帧的解码顺序和应该要显示的顺序是不同的，因为 B 帧的解码需要依赖其后面的 I 或 P 帧

<img src="E:\ljj的博客\pictures source\微信图片_20211016111923.jpg" alt="微信图片_20211016111923" style="zoom:33%;" />

本文虽然内容很简单，但对于初入应用层的业务开发来说已经足够了~（如想了解更多音视频原理部分，请参考本人其余博客 在写了`.jpg`）